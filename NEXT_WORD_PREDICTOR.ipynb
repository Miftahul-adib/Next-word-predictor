{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Miftahul-adib/Next-word-predictor/blob/faq-change/NEXT_WORD_PREDICTOR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "XwlopGlGX8JK"
      },
      "outputs": [],
      "source": [
        "faqs = \"\"\"\n",
        "\n",
        "Artificial Intelligence (AI), a field that was once limited to science fiction, has now become an integral part of modern life, powering everything from recommendation engines and chatbots to autonomous vehicles and medical diagnostics, and the roadmap for its future is both vast and transformative.\n",
        "As we stand at the edge of this technological revolution, it's crucial to understand where AI is today, where it’s heading, and the multifaceted disciplines surrounding it like data science, machine learning (ML), deep learning, and emerging fields such as reinforcement learning, generative AI, and responsible AI.\n",
        "The journey begins with data—the foundation of all AI systems.\n",
        "\n",
        "With the exponential increase in data availability from digital devices, social media, sensors, and connected systems, the world generates petabytes of data daily, and data science plays the role of extracting meaning from this sea of information.\n",
        "At its core, data science blends statistical analysis, data engineering, visualization, and machine learning to generate insights that can be used for decision-making or automation.\n",
        "A typical AI roadmap for someone entering the field includes first gaining a strong foundation in mathematics—especially linear algebra, calculus, statistics, and probability—as well as programming skills in Python, which is the de facto language of AI development due to its rich ecosystem of libraries like NumPy, pandas, scikit-learn, TensorFlow, and PyTorch.\n",
        "Once the basics are in place, the learner typically moves into supervised and unsupervised machine learning algorithms, learning about classification, regression, clustering, and dimensionality reduction.\n",
        "From there, the roadmap diverges into specialized areas: deep learning for neural networks and computer vision; natural language processing (NLP) for language models and AI-generated content; reinforcement learning for autonomous agents and gaming; and big data tools like Apache Spark and Hadoop for handling large-scale data processing.\n",
        "But building models is just one side of the coin—the deployment and maintenance of models is equally important, which brings in the field of MLOps (Machine Learning Operations), a set of practices combining ML with DevOps to ensure scalable and reliable AI systems.\n",
        "As we look ahead, the future of AI seems poised for a paradigm shift with the advent of large language models (LLMs) like GPT, Claude, and Gemini, which can understand and generate human language at an unprecedented level.\n",
        "These models are already transforming industries like education, customer support, legal, healthcare, finance, and even creative fields such as writing, art, and music.\n",
        "AI is no longer just about automating repetitive tasks but is now augmenting human capabilities—helping doctors diagnose complex diseases, assisting students with personalized tutoring, enabling businesses to forecast trends, and even co-writing code with developers.\n",
        "The possibilities seem endless: autonomous drones delivering goods, AI companions helping people with mental health, predictive systems mitigating climate change impacts, and generative AI revolutionizing entertainment and content creation.\n",
        "However, with such immense power comes equally significant challenges and responsibilities.\n",
        "Ethical concerns about privacy, bias, misinformation, surveillance, and displacement of jobs due to automation have sparked global debates.\n",
        "Hence, responsible AI—an area focused on fairness, transparency, interpretability, and accountability—is becoming a critical part of any AI roadmap.\n",
        "Governments, corporations, and academia are now collaborating on setting up ethical frameworks, AI policies, and regulatory guidelines to ensure that AI development remains aligned with human values and societal good.\n",
        "Education and lifelong learning will also play a key role in the AI-driven future.\n",
        "As AI transforms the job market, reskilling and upskilling will be essential, and interdisciplinary knowledge—combining domain expertise with AI—will be highly valuable.\n",
        "For instance, bioinformatics combines biology with machine learning; fintech applies AI in finance; and lawtech uses NLP to analyze legal documents.\n",
        "Similarly, hybrid professions will emerge where domain experts work alongside AI systems as decision facilitators.\n",
        "Another key future direction is explainable AI (XAI), which aims to open the “black box” of complex models and allow users to understand how decisions are made.\n",
        "This is crucial for trust, especially in high-stakes domains like healthcare and law.\n",
        "Meanwhile, the integration of quantum computing and AI promises a new era of hyper-advanced computation, allowing us to solve problems currently beyond the reach of classical computers.\n",
        "On a broader societal level, AI’s role in sustainability, education, governance, and inclusion is gaining attention.\n",
        "Smart agriculture powered by AI can improve crop yields and reduce resource usage.\n",
        "AI-driven analytics can help governments design better policies and public services.\n",
        "AI-enabled education platforms can personalize learning for millions of underserved students across the globe.\n",
        "Simultaneously, the democratization of AI through open-source platforms and low-code tools is enabling startups, researchers, and individuals—even in developing regions—to innovate without needing access to massive computational infrastructure.\n",
        "In the corporate world, AI is being embedded across every function—from marketing and supply chain optimization to HR analytics and risk assessment.\n",
        "Real-time analytics, predictive maintenance, intelligent process automation, and customer segmentation are just a few use cases where businesses are leveraging AI to boost efficiency and customer satisfaction.\n",
        "Cloud platforms like AWS, Google Cloud, and Azure offer scalable AI services like AutoML, custom model training, and pre-built APIs for vision, speech, and text, making enterprise AI adoption faster and easier than ever.\n",
        "At the same time, AI for social good is emerging as a powerful movement—using machine learning to tackle humanitarian issues such as disaster response, poverty detection, disease surveillance, and wildlife conservation.\n",
        "In healthcare, AI models can now detect cancers, analyze X-rays, predict patient deterioration, and accelerate drug discovery.\n",
        "In law enforcement and security, AI can help identify fraudulent transactions or detect cyber threats.\n",
        "Yet, as these systems become more autonomous and deeply integrated into society, questions about control, consent, and governance become vital.\n",
        "Global organizations like the UN, OECD, and IEEE are working on AI principles to ensure safe and beneficial development.\n",
        "Furthermore, there's growing interest in neurosymbolic AI—a hybrid of deep learning and symbolic reasoning—aiming to bring the best of both paradigms: the flexibility of neural networks with the logical rigor of symbolic systems.\n",
        "Another emerging direction is edge AI, where models are deployed on devices like smartphones and sensors instead of the cloud, enabling faster processing, enhanced privacy, and offline capabilities.\n",
        "With advances in tinyML and on-device optimization, real-time AI applications—from smart cameras and voice assistants to IoT devices and AR/VR systems—are becoming more viable.\n",
        "The AI roadmap also includes progress in multi-modal AI (combining text, images, audio, video inputs), continual learning (models that learn over time), federated learning (training across decentralized data), and AI agents capable of planning and executing long sequences of tasks.\n",
        "In fact, recent breakthroughs in agents and autonomous systems hint at a future where software not only assists humans but collaborates with them, adapts to new scenarios, and even self-improves.\n",
        "As we move toward Artificial General Intelligence (AGI)—systems with human-level reasoning across diverse tasks—philosophical, psychological, and existential questions will arise.\n",
        "Can machines be conscious?\n",
        "How do we align superintelligent systems with human values?\n",
        "What happens when machines outperform humans not just in speed, but also in creativity, empathy, and reasoning?\n",
        "These are no longer sci-fi musings but pressing challenges requiring multidisciplinary research.\n",
        "The future of AI, therefore, is not just technical but deeply human.\n",
        "It involves engineers and ethicists, artists and policy-makers, educators and entrepreneurs—all working together to shape the most powerful technology of our time.\n",
        "In conclusion, the roadmap of AI is an evolving journey of knowledge, creativity, and responsibility.\n",
        "From mastering core skills in mathematics, statistics, and programming to exploring specialized domains like computer vision, NLP, and reinforcement learning, and eventually addressing real-world problems with a focus on ethics, interpretability, and scalability—AI offers limitless possibilities.\n",
        "But whether these possibilities lead to a utopia of abundance or a dystopia of inequality will depend on how we, as a global community, choose to build, regulate, and share this technology.\n",
        "With the right education, governance, and mindset, AI can be the greatest tool humanity has ever created—not just for automation, but for amplification—for solving our hardest problems, expanding our collective intelligence, and co-creating a future that works for all.\n",
        "\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing the text"
      ],
      "metadata": {
        "id": "mvdLOpvdv9gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "XsNFyl4SYUkT"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer()"
      ],
      "metadata": {
        "id": "EldQ_6fXYUoI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "0J2v3m0VYUr3"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in faqs.split('\\n'):\n",
        "  tokenized_sentences=(tokenizer.texts_to_sequences([sentence]))\n",
        "\n"
      ],
      "metadata": {
        "id": "KWAA3KsNbOGC"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences=[]\n",
        "for sentence in faqs.split('\\n'):\n",
        "  tokenized_sentences=(tokenizer.texts_to_sequences([sentence]))[0]\n",
        "  for i in range (1,len(tokenized_sentences)):\n",
        "    input_sequences.append(tokenized_sentences[:i+1])"
      ],
      "metadata": {
        "id": "8QSqszmAfY4v"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "max_len = max(len(x) for x in input_sequences)\n",
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP9E2Xhhgk-L",
        "outputId": "813b340e-46a7-454f-f7ee-51d84c968f73"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input=pad_sequences(input_sequences,maxlen=max_len,padding='pre')"
      ],
      "metadata": {
        "id": "cAK1agXkkx1C"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=padded_input[:,:-1]\n",
        "y=padded_input[:,-1]"
      ],
      "metadata": {
        "id": "Laxfk4x1mryw"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb-Pyxu4nQMl",
        "outputId": "a8222167-9386-4230-f564-181f9f6cb894"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1286, 52)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdHX1jpUnvdC",
        "outputId": "65fab9ec-def2-4b6f-ac1a-c10c6f78727d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1286,)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim=len(tokenizer.word_index)\n",
        "input_dim=len(tokenizer.word_index)+1\n",
        "\n",
        "\n",
        "max_len = max(len(x) for x in input_sequences)\n",
        "input_length=max_len-1\n",
        "\n",
        "print(input_dim)\n",
        "print(input_length)\n",
        "print(max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY8q0-fust4E",
        "outputId": "dacfe622-3f38-42dc-b571-b8a694b127a4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "682\n",
            "52\n",
            "53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y=to_categorical(y,num_classes=input_dim)"
      ],
      "metadata": {
        "id": "lGsq2ZannwN5"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay-mPBP4WCHF",
        "outputId": "cadeaddb-e7d2-4675-814c-49083f246444"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1286, 682)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y9mjGkmSoCT0"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM ,Embedding"
      ],
      "metadata": {
        "id": "bPWn6Vr-o-Rj"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(x) for x in input_sequences)\n",
        "max_len\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKyocvglowFc",
        "outputId": "fb1f4e18-9bca-429c-fa89-6708d2c21ddc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim=len(tokenizer.word_index)+1\n",
        "\n",
        "\n",
        "max_len = max(len(x) for x in input_sequences)\n",
        "input_length=max_len-1\n",
        "\n",
        "print(input_dim)\n",
        "print(input_length)\n",
        "print(max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TVaidTCqv7N",
        "outputId": "b0355514-7858-483e-a24e-eaeeb584a759"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "682\n",
            "52\n",
            "53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building using LSTM"
      ],
      "metadata": {
        "id": "BbP2PWtqv3FO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim=len(tokenizer.word_index)+1\n",
        "\n",
        "\n",
        "max_len = max(len(x) for x in input_sequences)\n",
        "input_length=max_len-1\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense,Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(input_length,)))  # Input layer\n",
        "model.add(Embedding(input_dim=input_dim, output_dim=100,input_length=input_length))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(input_dim, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "DK5mUao3RHM_",
        "outputId": "7747dc81-688d-44f2-8d3c-71e1baa646dc"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m68,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m682\u001b[0m)            │       \u001b[38;5;34m102,982\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">68,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">682</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,982</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m321,782\u001b[0m (1.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321,782</span> (1.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m321,782\u001b[0m (1.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321,782</span> (1.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-on21S8TOaT",
        "outputId": "973b615d-226b-4c7a-93b3-68087a917ab2"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - accuracy: 0.0409 - loss: 6.4596\n",
            "Epoch 2/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - accuracy: 0.0514 - loss: 6.0198\n",
            "Epoch 3/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 92ms/step - accuracy: 0.0542 - loss: 5.9589\n",
            "Epoch 4/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 123ms/step - accuracy: 0.0628 - loss: 5.8797\n",
            "Epoch 5/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 90ms/step - accuracy: 0.0736 - loss: 5.7873\n",
            "Epoch 6/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 0.0677 - loss: 5.6707\n",
            "Epoch 7/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - accuracy: 0.0688 - loss: 5.4908\n",
            "Epoch 8/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 91ms/step - accuracy: 0.0788 - loss: 5.3254\n",
            "Epoch 9/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 91ms/step - accuracy: 0.1013 - loss: 5.0772\n",
            "Epoch 10/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - accuracy: 0.1258 - loss: 4.7821\n",
            "Epoch 11/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 90ms/step - accuracy: 0.1407 - loss: 4.5886\n",
            "Epoch 12/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 90ms/step - accuracy: 0.1600 - loss: 4.3664\n",
            "Epoch 13/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - accuracy: 0.1379 - loss: 4.2834\n",
            "Epoch 14/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.1847 - loss: 3.9754\n",
            "Epoch 15/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.2047 - loss: 3.8213\n",
            "Epoch 16/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 124ms/step - accuracy: 0.2626 - loss: 3.5505\n",
            "Epoch 17/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 90ms/step - accuracy: 0.3116 - loss: 3.4135\n",
            "Epoch 18/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.3825 - loss: 3.1886\n",
            "Epoch 19/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.3947 - loss: 3.0456\n",
            "Epoch 20/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.4854 - loss: 2.8242\n",
            "Epoch 21/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - accuracy: 0.5249 - loss: 2.7070\n",
            "Epoch 22/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 91ms/step - accuracy: 0.5762 - loss: 2.5317\n",
            "Epoch 23/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.6171 - loss: 2.3015\n",
            "Epoch 24/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 122ms/step - accuracy: 0.6584 - loss: 2.1438\n",
            "Epoch 25/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 92ms/step - accuracy: 0.7207 - loss: 1.9980\n",
            "Epoch 26/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 92ms/step - accuracy: 0.7321 - loss: 1.8888\n",
            "Epoch 27/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 102ms/step - accuracy: 0.7912 - loss: 1.6866\n",
            "Epoch 28/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.8015 - loss: 1.6413\n",
            "Epoch 29/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.8264 - loss: 1.5069\n",
            "Epoch 30/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 90ms/step - accuracy: 0.8579 - loss: 1.4041\n",
            "Epoch 31/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 91ms/step - accuracy: 0.8739 - loss: 1.2852\n",
            "Epoch 32/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 127ms/step - accuracy: 0.8918 - loss: 1.1737\n",
            "Epoch 33/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 91ms/step - accuracy: 0.9028 - loss: 1.1182\n",
            "Epoch 34/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 102ms/step - accuracy: 0.9094 - loss: 1.0289\n",
            "Epoch 35/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.9091 - loss: 0.9619\n",
            "Epoch 36/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - accuracy: 0.9318 - loss: 0.8626\n",
            "Epoch 37/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.9500 - loss: 0.8047\n",
            "Epoch 38/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.9422 - loss: 0.7387\n",
            "Epoch 39/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.9499 - loss: 0.6977\n",
            "Epoch 40/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - accuracy: 0.9499 - loss: 0.6632\n",
            "Epoch 41/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 0.9630 - loss: 0.5925\n",
            "Epoch 42/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 90ms/step - accuracy: 0.9610 - loss: 0.5657\n",
            "Epoch 43/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 125ms/step - accuracy: 0.9634 - loss: 0.5292\n",
            "Epoch 44/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 0.9599 - loss: 0.5055\n",
            "Epoch 45/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - accuracy: 0.9701 - loss: 0.4567\n",
            "Epoch 46/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step - accuracy: 0.9726 - loss: 0.4249\n",
            "Epoch 47/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 92ms/step - accuracy: 0.9671 - loss: 0.4166\n",
            "Epoch 48/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.9799 - loss: 0.3661\n",
            "Epoch 49/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.9740 - loss: 0.3531\n",
            "Epoch 50/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.9825 - loss: 0.3321\n",
            "Epoch 51/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - accuracy: 0.9836 - loss: 0.3188\n",
            "Epoch 52/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 0.9797 - loss: 0.3122\n",
            "Epoch 53/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9782 - loss: 0.2833\n",
            "Epoch 54/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.9758 - loss: 0.2658\n",
            "Epoch 55/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.9774 - loss: 0.2551\n",
            "Epoch 56/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - accuracy: 0.9846 - loss: 0.2294\n",
            "Epoch 57/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.9843 - loss: 0.2332\n",
            "Epoch 58/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 123ms/step - accuracy: 0.9786 - loss: 0.2188\n",
            "Epoch 59/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.9878 - loss: 0.1951\n",
            "Epoch 60/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 91ms/step - accuracy: 0.9857 - loss: 0.1897\n",
            "Epoch 61/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - accuracy: 0.9762 - loss: 0.1967\n",
            "Epoch 62/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 90ms/step - accuracy: 0.9748 - loss: 0.1980\n",
            "Epoch 63/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.9808 - loss: 0.1820\n",
            "Epoch 64/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 0.9891 - loss: 0.1551\n",
            "Epoch 65/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.9912 - loss: 0.1427\n",
            "Epoch 66/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - accuracy: 0.9792 - loss: 0.1490\n",
            "Epoch 67/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.9858 - loss: 0.1345\n",
            "Epoch 68/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.9840 - loss: 0.1333\n",
            "Epoch 69/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - accuracy: 0.9813 - loss: 0.1275\n",
            "Epoch 70/70\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - accuracy: 0.9847 - loss: 0.1243\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7beea29111d0>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the model"
      ],
      "metadata": {
        "id": "hpuyz53XwMe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text= \"Ai is transforming the \"\n",
        "\n",
        "token_text=tokenizer.texts_to_sequences([text])\n",
        "\n",
        "padded_token_text=pad_sequences(token_text,maxlen=56,padding='pre')\n",
        "\n",
        "import numpy as np\n",
        "prediction=(np.argmax(model.predict(padded_token_text))).item()\n",
        "\n",
        "for word,index in tokenizer.word_index.items():\n",
        "  if index==prediction:\n",
        "    print(word)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kLDtrLiUrq5",
        "outputId": "0a69987b-4507-4d10-f4c5-32beac28c8fc"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step\n",
            "field\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "text= \"Natural Language Processing\"\n",
        "for i in range(15):\n",
        "\n",
        "\n",
        "  token_text=tokenizer.texts_to_sequences([text])\n",
        "\n",
        "  padded_token_text=pad_sequences(token_text,maxlen=56,padding='pre')\n",
        "\n",
        "  prediction=(np.argmax(model.predict(padded_token_text))).item()\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index==prediction:\n",
        "      text=text+\" \"+ word\n",
        "      print(text)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56FOdXtBf8bc",
        "outputId": "ad5b8c95-d324-41c9-e45d-2cf322a6142b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "Natural Language Processing align\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
            "Natural Language Processing align superintelligent\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "Natural Language Processing align superintelligent systems\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
            "Natural Language Processing align superintelligent systems with\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "Natural Language Processing align superintelligent systems with human\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
            "Natural Language Processing align superintelligent systems with human values\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "Natural Language Processing align superintelligent systems with human values and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
            "Natural Language Processing align superintelligent systems with human values and reasoning\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
            "Natural Language Processing align superintelligent systems with human values and reasoning across\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "Natural Language Processing align superintelligent systems with human values and reasoning across the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Natural Language Processing align superintelligent systems with human values and reasoning across the advent\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Natural Language Processing align superintelligent systems with human values and reasoning across the advent of\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Natural Language Processing align superintelligent systems with human values and reasoning across the advent of large\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Natural Language Processing align superintelligent systems with human values and reasoning across the advent of large language\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "Natural Language Processing align superintelligent systems with human values and reasoning across the advent of large language models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9SfPS_7ck87Q"
      },
      "execution_count": 53,
      "outputs": []
    }
  ]
}